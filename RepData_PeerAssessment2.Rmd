---
title: 'Reproducible Research - Peer Assessment 2: Analyse of the storm impact on health and economy'
output: html_document
---

## Synopsis
babla

## Settings
```{r setoptions, echo=TRUE, message = FALSE, warning = FALSE}
library("knitr") 
#set general options
opts_chunk$set(echo=TRUE, message = FALSE, warning = FALSE, fig.height=6, fig.width=12, fig.path='figure/', cache.path='cache/')
```

```{r library}
require("R.utils")
require("plyr")
require("lubridate")
require("reshape2")
require("ggplot2")
```

```{r functions}
##functions
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
```

## Data Processing
### Getting and Loading Data
From cousera reproductible research course, get the storm data file in a bzip archive format and extract it.

```{r get-extract}
urlfile <- "http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
zipfile <- "repdata-data-StormData.csv.bz2"
csvfile <- "repdata-data-StormData.csv"

if (!file.exists(zipfile))
  download.file(urlfile, destfile=zipfile)

if (!file.exists(zipfile))
  bunzip2("repdata-data-StormData.csv.bz2", overwrite=T, remove=F)
```

The csv file is very large (over 500 MB), few rows are read and a vector off classes is created then the entire csv with colClasses param is read.
```{r load, cache=TRUE}
##open large file
small = read.csv(file = csvfile, header = TRUE, nrow=5, stringsAsFactors=FALSE);
classes = sapply(small,class)

##got problem with the vector off classes and replace numeric, logic column by character column
classes["BGN_TIME"]<- "character"
classes["F"]<- "character"
classes[classes == "logical"] = "character"

data = read.csv(file = csvfile, header = TRUE, na.strings = "", colClasses = classes, stringsAsFactors=FALSE);
```
### First analyse

```{r first1, cache=TRUE}
##number of observations
data_dim <- dim(data)
data_dim
num_rows <- data_dim[1]
num_cols <- data_dim[2]

##column names
colnames(data)
```

There are ``r format(num_rows, big.mark=" ")`` observations and ``r num_cols`` columns.

### Cleaning data
```{r clean1, cache=TRUE}
##eliminate row with no event
data <- subset(data, FATALITIES > 0 | INJURIES > 0 | PROPDMG > 0 | CROPDMG > 0)

##keep usefull columns
data <- data[,c("BGN_DATE","STATE","EVTYPE","FATALITIES","INJURIES","PROPDMG","PROPDMGEXP","CROPDMG","CROPDMGEXP")]

##extract year
data$YEAR <- year(mdy_hms(data$BGN_DATE, truncated = 3))
````
After cleaning observation with no events and keep only interresting columns, we extract year from the BGN_DATE column and estimate the number of events by year.

```{r histo1}
##histogram of the storm frequency by year in US
histo <- ggplot(data, aes(x= YEAR)) +
  geom_histogram(fill="lightblue", colour="black", binwidth=1) +  
  xlab("Year") + ylab("frequency") + 
  ggtitle("Storm frequency by year in US")
histo
```


```{r clean2}
##aggregate data and keep the min year where events greater or equal to 10000 
c<-ddply(data, .(YEAR), summarise, count = length(YEAR) )
min_year <- min(c[c$count >= 10000,])
min_year

##filter
data <-subset(data, YEAR >= min_year)

##number of observations
data_dim <- dim(data)
data_dim

```
Based on the above histogram, the number of events significatly change (10 000 observations) arround ``r min_year``. We decided to subset and get ``r format(dim(data)[1], big.mark=" ")`` observations.

```{r clean3}
##cleanig events type
data$EVTYPE <- toupper(tolower(data$EVTYPE))
data$EVTYPE <- gsub("  "," ", x = data$EVTYPE)
data$EVTYPE <- trim(data$EVTYPE)
data$EVTYPE[grep("HURRICANE*", data$EVTYPE)] = "HURRICANE (TYPHOON)"
data$EVTYPE[grep("FLASH FLOOD*", data$EVTYPE)] = "FLASH FLOOD"
data$EVTYPE[grep("FLOOD/FLASH*", data$EVTYPE)] = "FLASH FLOOD"
data$EVTYPE[grep("WATERSPOUT*", data$EVTYPE)] = "WATERSPOUT"
data$EVTYPE[grep("TORNADO*", data$EVTYPE)] = "TORNADO"
data$EVTYPE[grep("WINTER STORM*", data$EVTYPE)] = "WINTER STORM"
data$EVTYPE[grep("TROPICAL STORM*", data$EVTYPE)] = "TROPICAL STORM"
data$EVTYPE[grep("HEAVY RAIN*", data$EVTYPE)] = "HEAVY RAIN"
data$EVTYPE[grep("HEAVY SNOW*", data$EVTYPE)] = "HEAVY SNOW"
data$EVTYPE[grep("TSTM WIND*", data$EVTYPE)] = "THUNDERSTORM WIND"
data$EVTYPE[grep("THUNDERSTORM WIND*", data$EVTYPE)] = "THUNDERSTORM WIND"
data$EVTYPE[grep("THUNDERSTORM[A-Z]+ WIND*", data$EVTYPE)] = "THUNDERSTORM WIND"
data$EVTYPE[grep("^HAIL", data$EVTYPE)] = "HAIL"
data$EVTYPE[grepl("HAIL", data$EVTYPE) & data$EVTYPE != "MARINE HAIL"]  = "HAIL"
```

## Results
### Compute inflation rate, property damage coefficient and crop damage coefficient
```{r, cache=TRUE}
csvCPIurl <- "https://www.quandl.com/api/v1/datasets/RATEINF/CPI_USA.csv"
csvCPIfile <- "CPI_USA.csv"

##downloading CPI CSV
if (!file.exists(zipfile))
  download.file(urlfile, destfile=zipfile)

##read csv
##read CPI CSV file
us_cpi <- read.csv(csvCPIfile)

#aggregate by year
us_cpi$YEAR <- year(ymd(us_cpi$Date))
agg_us_cpi <- ddply(us_cpi,.(YEAR), summarise, CPIm=mean(CPI))

#duplicate CPI data and merge with 1 year gap
agg_us_cpi_1 <- agg_us_cpi[-1,]
agg_us_cpi_1$YEAR <- agg_us_cpi_1$YEAR - 1
colnames(agg_us_cpi_1)[2] <- "CPIm_1"
agg_us_cpi <- merge(x= agg_us_cpi, y = agg_us_cpi_1, by.x = "YEAR")
agg_us_cpi$rates <- (agg_us_cpi$CPIm_1 - agg_us_cpi$CPIm)/agg_us_cpi$CPIm * 100

us_rates <- agg_us_cpi[,c(1,4)]


##estimate coef for damage
coef_propdmg <- data.frame(PROPDMGEXP=c("H","K","M","B","+","-","?",as.character(0:8)),
                           coef_prop=c(100,1000,10^6,10^9,1,0,0,rep(1,9))
)
coef_cropdmg <- data.frame(CROPDMGEXP=c("H","K","M","B","+","-","?",as.character(0:8)),
                           coef_crop=c(100,1000,10^6,10^9,1,0,0,rep(1,9))
)
##merge coef with data
data<- merge(x = data, y = coef_propdmg, by = "PROPDMGEXP", all.x = TRUE)
data<- merge(x = data, y = coef_cropdmg, by = "CROPDMGEXP", all.x = TRUE)

##merge with us inflation rates
data<- merge(x = data, y = us_rates, by = "YEAR", all.x = TRUE)
```

### Question 1 : Across the United States, which types of events are most harmful with respect to population health?
```{r prepro1, cache=TRUE}
## Aggregate fatalities and injuries and show the top 10
d <- ddply(data, .(EVTYPE), summarise, 
                      FATALITIES = sum(FATALITIES, na.rm = TRUE),
                      INJURIES = sum(INJURIES, na.rm = TRUE),
                      TOTAL = INJURIES + FATALITIES)

d<-d[order(-d$TOTAL),]
t<- head(d, n = 10)
t
```

Aggregate fatalities and injuries and show the top 10.

```{r plot1}
m<- melt(t)
harm <- ggplot(data = m,aes(x=EVTYPE, y=value, fill=factor(variable)), color=factor(variable)) + 
  stat_summary(fun.y = sum, position = position_dodge(), geom = "bar") +
  theme(axis.text.x = element_text(angle = 45,hjust = 1)) +
  ylab("Number of injuries / fatalities") + xlab("Event type")+
  guides(fill=guide_legend(title=NULL))
harm
```

Based on the above histogram, Tornado cause the most human damage.

### Question 2:Across the United States, which types of events have the greatest economic consequences?
```{r prepro2, cache=TRUE}
d <- ddply(data, .(EVTYPE), summarise, 
           PROPERTY_DAMAGE = sum(PROPDMG * coef_prop * rates, na.rm = TRUE),
           CROP_DAMAGE = sum(CROPDMG * coef_crop * rates, na.rm = TRUE),
           TOTAL = CROP_DAMAGE + PROPERTY_DAMAGE)

d<-d[order(-d$TOTAL),]
t<- head(d, n = 10)
t
```

Aggregate fatalities and injuries and show the top 10.

```{r plot2}
m<- melt(t)
eco <- ggplot(data = m,aes(x=EVTYPE, y=value, fill=factor(variable)), color=factor(variable)) + 
  stat_summary(fun.y = sum, position = position_dodge(), geom = "bar") +
  theme(axis.text.x = element_text(angle = 45,hjust = 1)) +
  ylab("Economic damage") + xlab("Event type")+
  guides(fill=guide_legend(title=NULL))
eco
```